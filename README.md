Ce document contient 3 dossiers qui constituent les étapes clés de notre algorithme

1)Tout d'abord une méthode de scrapping d'Inaturalist qui consiste à récupérer les images de ce site spécialisé en biologie. Il est codé de manière dynamique (style JavaScript) donc nous sommes obligé d'intégrer une méthode de scrolling qui consiste à 'descendre' au bout de chaque page, attendre la fin d'un chargement puis récupérer les images par une méthode wget et une étude du style CSS de la page.

2) Une fois ces images récupérer, nous pouvons alors entrainer notre réseau de neurones convolutif. Nous avons choisi un ResNet101, réseau particulièrement puissant (plusieurs millions de paramètres), un learning rate scheduler SGD auquel nous avons ajouté un ReduceLROnPlateau dans les cas où la loss serait 'bloquée' dans un extremum local. Après avoir splité notre dataset en trois ensemble on lance un entrainement.

3)Analyse de nos résultats. On analyse nos résultats de trois grandes manières:
-tout d'abord, une étude des metrics classiques du machine learning, c'est-à-dire le F1 score, l'accuracy, la precision et le recall. 

-Puis on étudie les éventuelles confusions entre les classes, ce qui pourrait nous donner par exemple des indications sur les ressemblances inter-espèces.

-Enfin, on met en place une méthode assez complexe, appelée méthode Grad-CAM, qui consiste à superposer une images à une matrices appelée heatmap que l'on a remplie de nuissance de rouge (en remplissant 0 et 0 pour les pixels blue et green et un nombre entre 0 et 1 pour le rouge). On a choisi la nuance de rouge que chaque coefficient du numpy array de heatmap devait porter en enlevant la dernière couche (couche dense de classification) de notre réseau convolutif et en s'intéressant à l'évolution du gradient de notre encodeur. Les zones de l'images auxquelles l'encodeurs accordaient le plus d'importance étant marquées par un fort gradient (impactant donc plus la loss dans la descente de gradient) sont alors notées avec un fort coeffcient dans la heatmap. Le résultat de la superposition de la heatmap avec l'image est assez intéressant puisqu'il permet de mettre en lumière les limites de la constitution de base de données par des méthodes de scrapping en deep learning, même lorsqu'il s'agit de site professionnels comme Inaturalist. En effet, on remarque par exemple sur une photo que c'est le pêcheur portant sont poisson qui est marqué le plus par le rouge, et non le poisson. Le réseau a dû apprendre à reconnaitre les pêcheurs car il devait certainement y en avoir beaucoup dans la base de données. Cela est mauvais car si une classe contient beaucoup de pêcheur portant des poissons elle risque d'être identifiée pour de mauvaises raisons et sera donc facilement confondues avec une photo d'une autre classe.